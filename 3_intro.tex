\chapter{Introduction}

High Energy Physics experiments involve large amount of complex systems subject to anomalies and malfunctioning. They generate a lot of high dimensional data that must be monitored and analysed by a Data Quality Monitoring team to validate and deliver certified data for physics analysis.

At the European Organization for Nuclear Research (CERN), the Compact Moun Solenoid (CMS) experiment in the Large Hadron Collider (LHC) generates more than 40 milions events per second, each one carrying payloads averaging 1 MB. It is the job of the Trigger System to discard the large majority of this data and retain the most interesting ones, having less than X microseconds to make decisions. 

The first level of this system restrict the output rate to 100 kHz, the upper limit imposed by the CMS readout electronics. The second level, implemented in software, further refines this stream, selecting an average rate of 400 Hz for offline event storage \cite{Khachatryan_2017}.

This phase is very delicate and sensible to malfunctions of each of the underlying experiment, from sub detectors to the trigger algorithms configurations.

In this work, we proceed to improve the current Rate Monitoring software, adding new features.

